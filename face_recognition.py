# -*- coding: utf-8 -*-
"""Face Recognition

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Bvv9bAypW0i-YN1bLDo4ryPPkvxk_s9G
"""

import os
import numpy as np
from PIL import Image
import matplotlib.pyplot as plt
from sklearn.cluster import KMeans
from sklearn.metrics import silhouette_score, davies_bouldin_score, calinski_harabasz_score
from sklearn.manifold import TSNE
import torch
import torch.nn as nn
import torch.optim as optim



# ----------- 1. Prepare Dataset -----------
def prepare_data_set(path):
    faces = []
    labels = []
    label = 1
    for root, dirnames, _ in os.walk(path):
        for subdirname in dirnames:
            subject_path = os.path.join(root, subdirname)
            print(f"Reading from: {subject_path}")
            for filename in os.listdir(subject_path):
                img_path = os.path.join(subject_path, filename)
                try:
                    img = Image.open(img_path).convert('L')  # grayscale
                    faces.append(np.asarray(img).ravel() / 255.0)
                    labels.append(label)
                except Exception as e:
                    print(f"Failed to load {img_path}: {e}")
            label += 1
    faces = np.array(faces)
    labels = np.array(labels)

    if len(faces) == 0:
        raise ValueError("No images loaded. Check your dataset path and structure.")

    return faces, labels

# ----------- 2. Autoencoder Definition -----------
class Autoencoder(nn.Module):
    def __init__(self, input_dim, hidden_dim):
        super(Autoencoder, self).__init__()
        self.encoder = nn.Sequential(
            nn.Linear(input_dim, 1000),
            nn.ReLU(),
            nn.Linear(1000, hidden_dim),
            nn.ReLU()
        )
        self.decoder = nn.Sequential(
            nn.Linear(hidden_dim, 1000),
            nn.ReLU(),
            nn.Linear(1000, input_dim),
            nn.Sigmoid()
        )

    def forward(self, x):
        encoded = self.encoder(x)
        decoded = self.decoder(encoded)
        return decoded

    def encode(self, x):
        return self.encoder(x)

# ----------- 3. Train Autoencoder -----------
def train_autoencoder(model, data, epochs=100, lr=0.05):
    data_tensor = torch.tensor(data, dtype=torch.float32)
    optimizer = optim.Adam(model.parameters(), lr=lr)
    loss_fn = nn.MSELoss()

    for epoch in range(epochs):
        optimizer.zero_grad()
        outputs = model(data_tensor)
        loss = loss_fn(outputs, data_tensor)
        loss.backward()
        optimizer.step()
        if epoch % 10 == 0 or epoch == epochs - 1:
            print(f"Epoch {epoch}/{epochs}, Loss: {loss.item():.4f}")

# ----------- 4. Evaluation Metrics -----------
def evaluate_clustering(embeddings, labels):
    unique_labels = np.unique(labels)
    if len(unique_labels) < 2:
        print("Only one cluster found. Skipping clustering evaluation.")
        return

    sil_score = silhouette_score(embeddings, labels)
    db_index = davies_bouldin_score(embeddings, labels)
    ch_index = calinski_harabasz_score(embeddings, labels)

    print(f"\n Clustering Evaluation:")
    print(f"Silhouette Score:         {sil_score:.4f}")
    print(f"Davies-Bouldin Index:     {db_index:.4f}")
    print(f"Calinski-Harabasz Index:  {ch_index:.4f}")

    # Plot the metrics
    plot_evaluation_metrics(sil_score, db_index, ch_index)

# ----------- 5. Plot Metrics as Bar Graph -----------
def plot_evaluation_metrics(sil_score, db_index, ch_index):
    # Prepare for visualization
    metrics = {
        "Silhouette": sil_score,
        "Davies-Bouldin (â†“)": 1 / db_index if db_index != 0 else 0,
        "Calinski-Harabasz": ch_index / 10000  # Normalize for display
    }

    plt.figure(figsize=(7, 5))
    bars = plt.bar(metrics.keys(), metrics.values(), color=['blue', 'red', 'green'])
    plt.title("Clustering Evaluation Metrics (Normalized)")
    plt.ylabel("Score (scaled)")
    plt.ylim(0, max(metrics.values()) * 1.2)

    # Annotate bars with actual values
    actual_values = [sil_score, db_index, ch_index]
    for bar, val in zip(bars, actual_values):
        plt.text(bar.get_x() + bar.get_width() / 2, bar.get_height() * 1.02,
                 f'{val:.4f}', ha='center', va='bottom')

    plt.tight_layout()
    plt.show()

# ----------- 6. Visualize Clusters -----------
def visualize_tsne(embeddings, cluster_labels, title='t-SNE Clustering'):
    tsne = TSNE(n_components=2, perplexity=30, n_iter=3000, random_state=42)
    reduced = tsne.fit_transform(embeddings)
    plt.figure(figsize=(8, 6))
    plt.scatter(reduced[:, 0], reduced[:, 1], c=cluster_labels, cmap='tab20', s=15)
    plt.title(title)
    plt.xlabel('Component 1')
    plt.ylabel('Component 2')
    plt.colorbar()
    plt.tight_layout()
    plt.show()

# ----------- 7. Main Pipeline -----------
def main():
    data_dir = r"/content/drive/MyDrive/face"
    faces, true_labels = prepare_data_set(data_dir)

    print(f"\n Loaded {len(faces)} images. Image size: {faces[0].shape[0]} pixels\n")
    input_dim = faces.shape[1]

    print("Training autoencoder...")
    hidden_dim = 500
    ae = Autoencoder(input_dim=input_dim, hidden_dim=hidden_dim)
    train_autoencoder(ae, faces, epochs=100, lr=0.05)

    print("Extracting compressed features...")
    with torch.no_grad():
        encoded_faces = ae.encode(torch.tensor(faces, dtype=torch.float32)).numpy()

    print("Applying K-Means clustering...")
    n_clusters = 40
    kmeans = KMeans(n_clusters=n_clusters, random_state=42, n_init=10)
    predicted_labels = kmeans.fit_predict(encoded_faces)

    unique = np.unique(predicted_labels)
    print(f"Unique clusters found: {len(unique)}")

    if len(unique) < 2:
        print("Not enough clusters found. Skipping evaluation and visualization.")
        return

    evaluate_clustering(encoded_faces, predicted_labels)
    visualize_tsne(encoded_faces, predicted_labels, title='t-SNE of Autoencoder + K-Means')

if __name__ == "__main__":
    main()

from google.colab import drive
drive.mount('/content/drive')